JOB_QUEUE=darwin@papilio
MAX_PROCESSORS=80
CONCURRENT_JOBS=4
JOB_PROCESSORS=`expr $MAX_PROCESSORS / $CONCURRENT_JOBS`
JOB_MEMORY=50G
QSUB_OPT="-m ae -M stagamak@oregonstate.edu"
BASE_DIR=/home/micro/stagamak/myData2/TEST
SEQ_DIR=/nfs2/hts/nextseq/211210_VH00571_45_AAAT7MYM5/L1
LINK_DIR=${BASE_DIR}/FastQs
TMP_DIR=${BASE_DIR}/Results
STORE_DIR=${HOME}/prod/prod_restructure/projects/stagamak/TEST

mkdir -p $LINK_DIR
mkdir -p $TMP_DIR

cd $LINK_DIR

symlinkFastqs -i $SEQ_DIR -d '-' -f 2

cd $BASE_DIR

### KneadData ### 
KNEAD_DB=/nfs3/Sharpton_Lab/public_databases/Homo_sapiens_hg37_and_human_contamination_Bowtie2_v0.1/hg37dec_v0.1
KNEAD_SEQS=${STORE_DIR}/KneadData_output
KNEAD_OTHER=${STORE_DIR}/KneadData_other
CMD_FILE="kneaddata_commands.txt"

mkdir -p $KNEAD_SEQS
mkdir -p $KNEAD_OTHER

generate_kneaddata_array_commands.sh \
    -i $LINK_DIR \
    -d $KNEAD_DB \
    -q $JOB_QUEUE \
    -o $STORE_DIR \
    -t $TMP_DIR \
    -p $JOB_PROCESSORS \
    -c $CONCURRENT_JOBS \
    -m $JOB_MEMORY \
    -b "$QSUB_OPT" \
    -f $CMD_FILE \
    -z
cp $CMD_FILE ${HOME}/Jobs

## Submit job with printed command from appropriate machine

cd $STORE_DIR

for FASTQ in *_paired_1.fastq.gz; do 
    SMPL=`echo $FASTQ | cut -d '-' -f 1`
    COUNT=`zcat $FASTQ | grep -c "@VH00571"`
    echo "${SMPL}: $COUNT"
done

mv *_paired_[12].fastq.gz $KNEAD_SEQS
mv *.gz $KNEAD_OTHER

### Humann ###

cd $LINK_DIR

rm ./*
symlinkFastqs -i $KNEAD_SEQS -d '-' -f 1 -m "*_1.fastq.gz"

cd $BASE_DIR

HUMANN_OUTPUT=${STORE_DIR}/Humann_output
CMD_FILE="humann_commands.txt"

mkdir -p $HUMANN_OUTPUT

### If need to install full knead database before running humann. Run the following
# INSTALL_LOCATION=/home/micro/stagamak/Sharpton_NFS/public_databases
# humann_databases --update-config yes --download chocophlan full $INSTALL_LOCATION

generate_humann3_array_commands.sh \
    -i $LINK_DIR \
    -t $TMP_DIR \
    -o $HUMANN_OUTPUT \
    -q $JOB_QUEUE \
    -p $JOB_PROCESSORS \
    -c $CONCURRENT_JOBS \
    -m $JOB_MEMORY \
    -f $CMD_FILE \
    -z
cp $CMD_FILE ${HOME}/Jobs

###### NEED TO ADD COMMANDS TO REMOVE *_humann_temp DIRS THAT ARE NOT MOVED TO STORAGE

## Submit job with printed command from appropriate machine

# ran some code in R to make tables of genefamily and pathways counts and coverages

cd $HUMANN_OUTPUT

OUTFILE=percent_unaligned.csv ###
touch $OUTFILE
echo "Sample,Type,Pct.unaligned" >> $OUTFILE

for TGZ in *tgz; do
    NAME=`echo $TGZ | cut -d '.' -f 1`
    SMPL=`echo $NAME | cut -d '-' -f 1`
    echo $SMPL
    LOG_PATH=`tar -zvtf $TGZ --wildcards --no-anchored '*.log' | cut -d ' ' -f 6`
    LOG_TOPDIR=`dirname $LOG_PATH | cut -d '/' -f 1`
    tar -zvxf $TGZ --wildcards --no-anchored '*.log'

    NUCL_UNAGLINED=`grep "Unaligned reads after nucleotide alignment" $LOG_PATH | grep -o "[0-9][0-9\.]* %" | sed 's/ %//'`
    echo "${SMPL},nucleotide,${NUCL_UNAGLINED}" >> $OUTFILE
    PROT_UNAGLINED=`grep "Unaligned reads after translated alignment" $LOG_PATH | grep -o "[0-9][0-9\.]* %" | sed 's/ %//'`
    echo "${SMPL},translated,${PROT_UNAGLINED}" >> $OUTFILE

    rm -rfv ./$LOG_TOPDIR
done